project: Head-Motion_LSTM-with-Sampling
name: cradle-01
version: null

hidden_size: 256
bottleneck_size: 64
lr: 5e-6

batch_size: 256
max_epochs: 60
optim_epochs: 100

use_centroid: True
use_angle: True
delta_order: 2
sample_rate: 16000
nfft: 400
shift: 160

data_dir: ???
no_cache_build: False
clear_cache: False

ckpt_path: ???
log_dir: ???

device: gpu

# model config
model:
    #feature config
    nmels: ${audio.nmels}
    delta_order: ${delta_order}
    use_centroid: ${use_centroid}
    use_angle: ${use_angle}

    # sampler config
    sampler_hidden_size: 128
    sampler_num_layers: 2
    sampler_dropout_rate: 0
    sampling_rate: ${sample_rate}
    shift: ${shift}
    fps: ${motion.fps}
    pred_fps: ${motion.pred_fps}

    # predicter config
    hidden_size: ${hidden_size}
    bottleneck_size: ${bottleneck_size}
    num_layers: 2
    num_lstm: 1
    dropout_rate: 0.0
    use_layer_norm: True
    use_relu: True
    use_mixing: False
    use_residual: True

    # general config
    delta_loss_scale: 1
    
    # loss config
    # mse, mae, huber, smoothl1
    loss_type: huber
    loss_reduction: mean
    huber_delta: 1.0
    smoothl1_beta: 1.0

    # scheduled sampling config
    use_scheduled_sampling: False
    max_epochs: ${max_epochs}

metrics:
    # feature info
    use_centroid: ${use_centroid}
    use_angle: ${use_angle}
    delta_order: ${delta_order}

trainer:
    accelerator: ${device}
    accumulate_grad_batches: 1
    benchmark: True
    deterministic: True
    check_val_every_n_epoch: 1
    default_root_dir: ${log_dir}
    devices: auto
    enable_checkpointing: True
    max_epochs: ${max_epochs}
    log_every_n_steps: 50
    precision: 32
    strategy: ddp
    val_check_interval: 0.25

logger:
    ckpt_path: ${ckpt_path}
    exp_name: ${name}
    project: ${project}
    save_dir: ${log_dir}
    version: ${version}

callbacks:
    save_top_k: 5
    patience_epoch: 10
    use_checkpoint: True
    use_early_stopping: True

optim:
    use_optimizer: adam
    momentum: 0.9
    weight_decay: 1e-2
    lr: ${lr}
    use_lr_sched: True
    batch_size: ${batch_size}
    max_epochs: ${optim_epochs}

exp:
    use_model: lstmformer
    use_amp: True
    batch_size: ${batch_size}
    train_rate: 0.8
    valid_rate: 0.1
    use_logger: wandb

data:
    # data build reguration
    no_cache_build: ${no_cache_build}
    clear_cache: ${clear_cache}

    data_dir: ${data_dir}
    fps: ${motion.fps}
    pred_fps: ${motion.pred_fps}
    pred_shift: ${motion.pred_shift}
    max_len: ${motion.max_len}
    min_len: ${motion.min_len}
    shift_len: ${motion.shift_len}
    leading_len: ${motion.leading_len}

    sample_rate: ${sample_rate}
    nfft: ${nfft}
    shift: ${shift}

    threshold: ${utterance.threshold}
    minimum_utterance_length: ${utterance.minimum_utterance_length}
    pause_with_voice: ${utterance.pause_with_voice}
    pause_without_voice: ${utterance.pause_without_voice}
    mergin: ${utterance.mergin}

    use_partner_motion: True
    use_partner_audio: True
    use_self_motion: True
    use_self_audio: False

    # target info
    target_shift: 1 # based on input frequency

    use_centroid: ${use_centroid}
    use_angle: ${use_angle}
    delta_order: ${delta_order}

motion:
    # data fps
    fps: 25
    # either pred_fps or pred_max_len should be set
    pred_fps: 12.5
    pred_shift: 2
    # len parameters based on fps
    max_len: 250
    min_len: 125
    shift_len: 250
    leading_len: 25
    # other parameters -> mr_gen.utils.preprocess.motion.MotionPreprocessor
    use_centroid: ${use_centroid}
    use_angle: ${use_angle}
    delta_order: ${delta_order}
    train_by_std: True

audio:
    sample_rate: ${sample_rate}
    nfft: ${nfft}
    shift: ${shift}
    nmels: 26
    delta_order: ${delta_order}

utterance:
    # fft parameters
    sample_rate: ${sample_rate}
    window_size: ${nfft}
    stride: ${shift}
    # voice activity detection parameters
    threshold: -4 # [log power]
    # utterance secton parameters
    minimum_utterance_length: 1.0 # [s]
    pause_with_voice: 1.0 # [s]
    pause_without_voice: 2.0 # [s]
    # turn section parameters
    mergin: 1.0 # [s]
    # other parameters
    exp_plot: False
    exp_plot_dir: "data/temp/utterance_section"

model_type: lstm_with_sampling
model_path: null
model_conf: null
movie_path: null
audio_path: null
output_path: null
